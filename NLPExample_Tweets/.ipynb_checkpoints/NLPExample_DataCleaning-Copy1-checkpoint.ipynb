{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Example, Twitter Tweets <img style=\"float: right; width: 310px;\" src=\"./Data/Twitter_Logo.jpg\"/>  \n",
    "  \n",
    "---  \n",
    "\n",
    "### By: Heather M. Steich, M.S.\n",
    "### Date: October 29$^{th}$, 2017\n",
    "### Written in: Python 3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.5 |Anaconda custom (64-bit)| (default, Jul  5 2016, 14:53:07) [MSC v.1600 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "## Dataset Credit  \n",
    "  \n",
    "  \n",
    "The data used for this project is used with permission (if cited) from the following source:  \n",
    "\n",
    "    Z. Cheng, J. Caverlee, and K. Lee. You Are Where You Tweet: A Content-Based Approach to Geo-locating Twitter Users. \n",
    "    In Proceeding of the 19th ACM Conference on Information and Knowledge Management (CIKM), Toronto, Oct 2010. (Bibtex)\n",
    "\n",
    "<https://archive.org/details/twitter_cikm_2010><img style=\"float: center;\" src=\"./Data/paper_logo.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "## Overview\n",
    "\n",
    "The goal of the exercise is to extract information about concert appearances of musicians, performers or bands.  For each such tweet, we are looking to extract:  \n",
    "\n",
    " - Who was the performer  \n",
    " - When was the show  \n",
    " - Where was the show  \n",
    " - The Tweeter user who attended it  \n",
    " - The sentiment of the tweet  \n",
    "   \n",
    "Not all of these fields are available in all tweets, and that’s ok.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset includes the user id who sent the tweet and the timestamp for the tweet. For the ‘when’ field, we are interested in the date of the show (not just the tweet). We are not interested in any other tweets, including tweets about performers which don’t mention concerts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "### Part 1: Classify if the tweets are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LOAD LIBRARIES\n",
    "\n",
    "# Data wrangling & processing: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning:\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestClassifier as RF\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from pandas_ml import ConfusionMatrix\n",
    "#from sklearn.metrics import roc_curve\n",
    "#from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "# Plotting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from IPython.display import display, HTML\n",
    "\n",
    "# Remove warning messages:\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ESTABLISH PLOT FORMATTING\n",
    "\n",
    "#mpl.rcdefaults()  # Resets plot defaults\n",
    "\n",
    "def plt_format():\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (16, 10)\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['axes.labelcolor'] = 'black'\n",
    "    plt.rcParams['axes.labelsize'] = 20\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titlesize'] = 32\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['legend.fontsize'] = 16\n",
    "    plt.rcParams['legend.markerscale'] = 4\n",
    "    plt.rcParams['text.color'] = 'black'\n",
    "    plt.rcParams['xtick.labelsize'] = 20\n",
    "    plt.rcParams['ytick.labelsize'] = 20\n",
    "    plt.rcParams['legend.fontsize'] = 16\n",
    "    plt.rcParams['legend.frameon'] = False\n",
    "    plt.rcParams['axes.linewidth'] = 1\n",
    "\n",
    "#plt.rcParams.keys()  # Available rcParams\n",
    "plt_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 2: Load, view & prepare the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (3822473, 1)\n",
      "Train Column Names: Index(['A'], dtype='object')\n",
      "\n",
      "Test Shape: (5150011, 1)\n",
      "Test Column Names: Index(['A'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## LOAD DATA:\n",
    "\n",
    "# Read in the files:\n",
    "train = pd.read_csv(\"./Data/training_set_tweets.txt\", delimiter=\"\\n\", names='A') \n",
    "test = pd.read_csv(\"./Data/test_set_tweets.txt\", delimiter=\"\\n\", names='A')\n",
    "\n",
    "# Print shapes:\n",
    "print('Train Shape:', train.shape)\n",
    "print('Train Column Names:', train.columns)\n",
    "print('\\nTest Shape:', test.shape)\n",
    "print('Test Column Names:', test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60730027\\t6320951896\\t@thediscovietnam coo.  t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60730027\\t6320673258\\t@thediscovietnam shit it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60730027\\t6319871652\\t@thediscovietnam hey cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60730027\\t6318151501\\t@smokinvinyl dang.  you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60730027\\t6317932721\\tmaybe i'm late in the ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   A\n",
       "0  60730027\\t6320951896\\t@thediscovietnam coo.  t...\n",
       "1  60730027\\t6320673258\\t@thediscovietnam shit it...\n",
       "2  60730027\\t6319871652\\t@thediscovietnam hey cod...\n",
       "3  60730027\\t6318151501\\t@smokinvinyl dang.  you ...\n",
       "4  60730027\\t6317932721\\tmaybe i'm late in the ga..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PRINT A PREVIEW OF THE DATAFRAMES:\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22077441\\t10538487904\\tOk today I have to find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22077441\\t10536835844\\tI am glad I'm having th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22077441\\t10536809086\\tHonestly I don't even k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22077441\\t10534149786\\t@LovelyJ_Janelle hey so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22077441\\t10530203659\\tSitting infront of this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   A\n",
       "0  22077441\\t10538487904\\tOk today I have to find...\n",
       "1  22077441\\t10536835844\\tI am glad I'm having th...\n",
       "2  22077441\\t10536809086\\tHonestly I don't even k...\n",
       "3  22077441\\t10534149786\\t@LovelyJ_Janelle hey so...\n",
       "4  22077441\\t10530203659\\tSitting infront of this..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DEFINE A FUNCTION TO PROPERLY STRUCTURE THE DATA:\n",
    "\n",
    "def restructure_data(df):\n",
    "    print('Starting phase 1!')\n",
    "    \n",
    "    global split_df\n",
    "    split_df = df['A'].str.split('\\t', 3, expand=True)\n",
    "    split_df.columns = ['UserID', 'tTweetID', 'tTweet', 'tCreatedAt']\n",
    "            \n",
    "    bad_rows = split_df[~split_df.UserID.str.isnumeric()].index\n",
    "            \n",
    "    while True:\n",
    "        if bad_rows.shape[0] > 0:\n",
    "            #print(' ', bad_rows.shape[0])\n",
    "                    \n",
    "            bad_rows = df.iloc[bad_rows, :]\n",
    "            bad_rows.index = bad_rows.index - 1\n",
    "                    \n",
    "            good_rows = split_df[split_df.UserID.str.isnumeric()].index\n",
    "            good_rows = df.iloc[good_rows, :]\n",
    "                    \n",
    "            combined_df = pd.concat([good_rows, bad_rows], axis=1)\n",
    "            combined_df.columns = ['A', 'B']\n",
    "                    \n",
    "            df = pd.DataFrame((combined_df['A'].fillna('') + \n",
    "                               combined_df['B'].fillna('')), \n",
    "                               columns=['A']).reset_index(drop=True)\n",
    "                    \n",
    "            split_df = df['A'].str.split('\\t', 3, expand=True)\n",
    "            split_df.columns = ['UserID', 'tTweetID', 'tTweet', 'tCreatedAt']\n",
    "            \n",
    "            bad_rows = split_df[~split_df.UserID.str.isnumeric()].index\n",
    "                \n",
    "        else:\n",
    "            print('Done with phase 1!')\n",
    "                    \n",
    "            bad_rows = split_df[split_df.tTweetID.isnull()].index\n",
    "\n",
    "            while True:\n",
    "                if bad_rows.shape[0] > 0:\n",
    "                    #print('  ', bad_rows.shape[0])\n",
    "                            \n",
    "                    bad_rows = df.iloc[bad_rows, :]\n",
    "                    bad_rows.index = bad_rows.index - 1\n",
    "\n",
    "                    good_rows = split_df[~split_df.tTweetID.isnull()].index\n",
    "                    good_rows = df.iloc[good_rows, :]\n",
    "\n",
    "                    combined_df = pd.concat([good_rows, bad_rows], axis=1)\n",
    "                    combined_df.columns = ['A', 'B']\n",
    "\n",
    "                    df = pd.DataFrame((combined_df['A'].fillna('') + \n",
    "                                       combined_df['B'].fillna('')), \n",
    "                                       columns=['A']).reset_index(drop=True)\n",
    "\n",
    "                    split_df = df['A'].str.split('\\t', 3, expand=True)\n",
    "                    split_df.columns = ['UserID', 'tTweetID', 'tTweet', 'tCreatedAt']\n",
    "\n",
    "                    bad_rows = split_df[split_df.tTweetID.isnull()].index\n",
    "\n",
    "                else:\n",
    "                    print('Done with phase 2!')\n",
    "                    \n",
    "                    bad_rows = split_df[~split_df.tTweetID.str.isnumeric()].index\n",
    "\n",
    "                    while True:\n",
    "                        if bad_rows.shape[0] > 0:\n",
    "                            #print('   ', bad_rows.shape[0])\n",
    "\n",
    "                            bad_rows = df.iloc[bad_rows, :]\n",
    "                            bad_rows.index = bad_rows.index - 1\n",
    "\n",
    "                            good_rows = split_df[split_df.tTweetID.str.isnumeric()].index\n",
    "                            good_rows = df.iloc[good_rows, :]\n",
    "\n",
    "                            combined_df = pd.concat([good_rows, bad_rows], axis=1)\n",
    "                            combined_df.columns = ['A', 'B']\n",
    "\n",
    "                            df = pd.DataFrame((combined_df['A'].fillna('') + \n",
    "                                               combined_df['B'].fillna('')), \n",
    "                                               columns=['A']).reset_index(drop=True)\n",
    "\n",
    "                            split_df = df['A'].str.split('\\t', 3, expand=True)\n",
    "                            split_df.columns = ['UserID', 'tTweetID', 'tTweet', 'tCreatedAt']\n",
    "\n",
    "                            bad_rows = split_df[~split_df.tTweetID.str.isnumeric()].index\n",
    "\n",
    "                        else:\n",
    "                            print('Done with phase 3!')\n",
    "                                    \n",
    "                            strip_timestamps = df['A'].str.rsplit('\\t', 1, expand=True)\n",
    "                            other_columns = strip_timestamps[0].str.split('\\t', 2, expand=True)\n",
    "                            split_df = pd.concat([other_columns, strip_timestamps[1]], axis=1)\n",
    "                            split_df.columns = ['UserID', 'tTweetID', 'tTweet', 'tCreatedAt']\n",
    "                                    \n",
    "                            split_df.UserID = split_df.UserID.astype(np.int64)\n",
    "                            split_df.tTweetID = split_df.tTweetID.astype(np.int64)\n",
    "                            split_df.tCreatedAt = pd.to_datetime(split_df.tCreatedAt) #split_df.tCreatedAt.astype(np.datetime64)\n",
    "                            \n",
    "                            print('Dataset completed!\\n')\n",
    "                            return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  80516\n",
      "  12604\n",
      "  3386\n",
      "  1302\n",
      "  607\n",
      "  319\n",
      "  168\n",
      "  91\n",
      "  49\n",
      "  19\n",
      "  8\n",
      "  6\n",
      "  5\n",
      "  3\n",
      "  1\n",
      "Done with phase 1!\n",
      "Done with phase 2!\n",
      "    22\n",
      "    7\n",
      "    5\n",
      "    3\n",
      "    2\n",
      "    1\n",
      "Done with phase 3!\n"
     ]
    }
   ],
   "source": [
    "## APPLY THE RESTRUCTURING FUNCTION TO THE TRAINING & TEST SETS:\n",
    "## (This will take several minutes to run.)\n",
    "\n",
    "train_df = restructure_data(train)\n",
    "test_df = restructure_data(test)\n",
    "\n",
    "# Print corrected shapes:\n",
    "print('Corrected Train Shape:', train_df.shape)\n",
    "print('\\nCorrected Test Shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 3: Validate that the restructured data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      " UserID                 int64\n",
      "tTweetID               int64\n",
      "tTweet                object\n",
      "tCreatedAt    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Testing:\n",
      " UserID                 int64\n",
      "tTweetID               int64\n",
      "tTweet                object\n",
      "tCreatedAt    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## CHECK DATA TYPES:\n",
    "\n",
    "print('Training:\\n', train_df.dtypes)\n",
    "print('\\nTesting:\\n', test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data in Training Set:\n",
      " 0\n",
      "Missing Data in Testing Set:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "## CHECK FOR MISSING VALUES:\n",
    "\n",
    "print('Missing Data in Training Set:\\n', train_df.isnull().sum().values.sum())\n",
    "print('Missing Data in Testing Set:\\n', test_df.isnull().sum().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='UserID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2189710</th>\n",
       "      <td>95260481</td>\n",
       "      <td>6470419090</td>\n",
       "      <td>get paid with paypal everyweek no hard work ne...</td>\n",
       "      <td>2009-12-08 12:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189709</th>\n",
       "      <td>95260481</td>\n",
       "      <td>6470548793</td>\n",
       "      <td>I get paid Online making about 12k a Month wor...</td>\n",
       "      <td>2009-12-08 12:14:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189708</th>\n",
       "      <td>95260481</td>\n",
       "      <td>6470585312</td>\n",
       "      <td>How is the new Jay-z album should i buy it or ...</td>\n",
       "      <td>2009-12-08 12:15:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189706</th>\n",
       "      <td>95260481</td>\n",
       "      <td>6470751598</td>\n",
       "      <td>What's this all about all I can say is you hav...</td>\n",
       "      <td>2009-12-08 12:22:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189734</th>\n",
       "      <td>95260481</td>\n",
       "      <td>6468176439</td>\n",
       "      <td>nearly my son's birthday he loves disney cars,...</td>\n",
       "      <td>2009-12-08 10:45:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID    tTweetID  \\\n",
       "2189710  95260481  6470419090   \n",
       "2189709  95260481  6470548793   \n",
       "2189708  95260481  6470585312   \n",
       "2189706  95260481  6470751598   \n",
       "2189734  95260481  6468176439   \n",
       "\n",
       "                                                    tTweet          tCreatedAt  \n",
       "2189710  get paid with paypal everyweek no hard work ne... 2009-12-08 12:10:01  \n",
       "2189709  I get paid Online making about 12k a Month wor... 2009-12-08 12:14:34  \n",
       "2189708  How is the new Jay-z album should i buy it or ... 2009-12-08 12:15:50  \n",
       "2189706  What's this all about all I can say is you hav... 2009-12-08 12:22:08  \n",
       "2189734  nearly my son's birthday he loves disney cars,... 2009-12-08 10:45:57  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='UserID').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119368</th>\n",
       "      <td>5622</td>\n",
       "      <td>28191</td>\n",
       "      <td>trying to figure out what this thing is.</td>\n",
       "      <td>2006-09-10 11:07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825210</th>\n",
       "      <td>38323</td>\n",
       "      <td>581203</td>\n",
       "      <td>Getting ready to go to the Improv Olympic to s...</td>\n",
       "      <td>2006-12-02 21:34:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663297</th>\n",
       "      <td>690103</td>\n",
       "      <td>3873613</td>\n",
       "      <td>Customer support is no fun at all.</td>\n",
       "      <td>2007-01-23 18:07:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663296</th>\n",
       "      <td>690103</td>\n",
       "      <td>3880013</td>\n",
       "      <td>I am still doing customer support</td>\n",
       "      <td>2007-01-23 19:01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663295</th>\n",
       "      <td>690103</td>\n",
       "      <td>3880323</td>\n",
       "      <td>Bryan is a nice guy cause he thinks I shouldn'...</td>\n",
       "      <td>2007-01-23 19:04:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  tTweetID                                             tTweet  \\\n",
       "119368     5622     28191           trying to figure out what this thing is.   \n",
       "825210    38323    581203  Getting ready to go to the Improv Olympic to s...   \n",
       "1663297  690103   3873613                 Customer support is no fun at all.   \n",
       "1663296  690103   3880013                  I am still doing customer support   \n",
       "1663295  690103   3880323  Bryan is a nice guy cause he thinks I shouldn'...   \n",
       "\n",
       "                 tCreatedAt  \n",
       "119368  2006-09-10 11:07:07  \n",
       "825210  2006-12-02 21:34:25  \n",
       "1663297 2007-01-23 18:07:29  \n",
       "1663296 2007-01-23 19:01:33  \n",
       "1663295 2007-01-23 19:04:58  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tTweetID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552720</th>\n",
       "      <td>22307857</td>\n",
       "      <td>6485532854</td>\n",
       "      <td>NYC at holiday time, can't go wrong. Ate with ...</td>\n",
       "      <td>2009-12-08 21:27:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738094</th>\n",
       "      <td>15676578</td>\n",
       "      <td>6485597908</td>\n",
       "      <td>Spoiler: Find out who won Biggest Loser! http:...</td>\n",
       "      <td>2009-12-08 21:29:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672933</th>\n",
       "      <td>22097952</td>\n",
       "      <td>6485873515</td>\n",
       "      <td>@katelynroseee hahaha. I mean, New York Style ...</td>\n",
       "      <td>2009-12-08 21:39:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108263</th>\n",
       "      <td>34739186</td>\n",
       "      <td>6486280798</td>\n",
       "      <td>WOW! Cardio Barre was AMAZING-I had no idea u ...</td>\n",
       "      <td>2009-12-08 21:54:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108262</th>\n",
       "      <td>34739186</td>\n",
       "      <td>6486831431</td>\n",
       "      <td>Stop tweeting while we're at dinner!!! ;) RT @...</td>\n",
       "      <td>2009-12-08 22:14:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID    tTweetID  \\\n",
       "552720   22307857  6485532854   \n",
       "1738094  15676578  6485597908   \n",
       "1672933  22097952  6485873515   \n",
       "108263   34739186  6486280798   \n",
       "108262   34739186  6486831431   \n",
       "\n",
       "                                                    tTweet          tCreatedAt  \n",
       "552720   NYC at holiday time, can't go wrong. Ate with ... 2009-12-08 21:27:36  \n",
       "1738094  Spoiler: Find out who won Biggest Loser! http:... 2009-12-08 21:29:53  \n",
       "1672933  @katelynroseee hahaha. I mean, New York Style ... 2009-12-08 21:39:27  \n",
       "108263   WOW! Cardio Barre was AMAZING-I had no idea u ... 2009-12-08 21:54:03  \n",
       "108262   Stop tweeting while we're at dinner!!! ;) RT @... 2009-12-08 22:14:24  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tTweetID').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166674</th>\n",
       "      <td>20192982</td>\n",
       "      <td>1251289107</td>\n",
       "      <td>!</td>\n",
       "      <td>2009-02-25 16:57:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353374</th>\n",
       "      <td>65642903</td>\n",
       "      <td>4123445005</td>\n",
       "      <td>!</td>\n",
       "      <td>2009-09-20 08:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76889</th>\n",
       "      <td>15863302</td>\n",
       "      <td>5658023171</td>\n",
       "      <td>!</td>\n",
       "      <td>2009-11-12 14:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161550</th>\n",
       "      <td>17926620</td>\n",
       "      <td>6287028586</td>\n",
       "      <td>!</td>\n",
       "      <td>2009-12-02 18:37:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218118</th>\n",
       "      <td>30681120</td>\n",
       "      <td>5744360824</td>\n",
       "      <td>!</td>\n",
       "      <td>2009-11-15 14:11:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID    tTweetID tTweet          tCreatedAt\n",
       "166674   20192982  1251289107      ! 2009-02-25 16:57:39\n",
       "3353374  65642903  4123445005      ! 2009-09-20 08:09:00\n",
       "76889    15863302  5658023171      ! 2009-11-12 14:00:34\n",
       "2161550  17926620  6287028586      ! 2009-12-02 18:37:42\n",
       "218118   30681120  5744360824      ! 2009-11-15 14:11:25"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tTweet').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2822022</th>\n",
       "      <td>29392455</td>\n",
       "      <td>4164281228</td>\n",
       "      <td>１日ほんの数ページずつですが、坂の上の雲を再読中、以前は完全に龍馬がゆく派だったが、変わったかも。</td>\n",
       "      <td>2009-09-21 22:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564787</th>\n",
       "      <td>22874169</td>\n",
       "      <td>4333563740</td>\n",
       "      <td>３年前酔っぱらってリバースしたコロナビール飲んでます。酒もってこーい！！</td>\n",
       "      <td>2009-09-23 22:35:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036928</th>\n",
       "      <td>52706200</td>\n",
       "      <td>4118931198</td>\n",
       "      <td>４月にサンディエゴで始まる予定のアニメのイベント。その名も「アニメ漢字」ーＡＮＩＭＥ　ＣＯＮ...</td>\n",
       "      <td>2009-09-20 00:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415132</th>\n",
       "      <td>14330200</td>\n",
       "      <td>3991134830</td>\n",
       "      <td>９月１５日、火曜日。曇り。</td>\n",
       "      <td>2009-09-14 18:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532366</th>\n",
       "      <td>34374919</td>\n",
       "      <td>4119614535</td>\n",
       "      <td>�Red' Sims will always love �his' boys: During...</td>\n",
       "      <td>2009-09-20 01:09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID    tTweetID  \\\n",
       "2822022  29392455  4164281228   \n",
       "3564787  22874169  4333563740   \n",
       "3036928  52706200  4118931198   \n",
       "3415132  14330200  3991134830   \n",
       "3532366  34374919  4119614535   \n",
       "\n",
       "                                                    tTweet          tCreatedAt  \n",
       "2822022  １日ほんの数ページずつですが、坂の上の雲を再読中、以前は完全に龍馬がゆく派だったが、変わったかも。 2009-09-21 22:09:00  \n",
       "3564787               ３年前酔っぱらってリバースしたコロナビール飲んでます。酒もってこーい！！ 2009-09-23 22:35:03  \n",
       "3036928  ４月にサンディエゴで始まる予定のアニメのイベント。その名も「アニメ漢字」ーＡＮＩＭＥ　ＣＯＮ... 2009-09-20 00:09:00  \n",
       "3415132                                      ９月１５日、火曜日。曇り。 2009-09-14 18:09:00  \n",
       "3532366  �Red' Sims will always love �his' boys: During... 2009-09-20 01:09:00  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tTweet').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119368</th>\n",
       "      <td>5622</td>\n",
       "      <td>28191</td>\n",
       "      <td>trying to figure out what this thing is.</td>\n",
       "      <td>2006-09-10 11:07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825210</th>\n",
       "      <td>38323</td>\n",
       "      <td>581203</td>\n",
       "      <td>Getting ready to go to the Improv Olympic to s...</td>\n",
       "      <td>2006-12-02 21:34:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663297</th>\n",
       "      <td>690103</td>\n",
       "      <td>3873613</td>\n",
       "      <td>Customer support is no fun at all.</td>\n",
       "      <td>2007-01-23 18:07:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663296</th>\n",
       "      <td>690103</td>\n",
       "      <td>3880013</td>\n",
       "      <td>I am still doing customer support</td>\n",
       "      <td>2007-01-23 19:01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663295</th>\n",
       "      <td>690103</td>\n",
       "      <td>3880323</td>\n",
       "      <td>Bryan is a nice guy cause he thinks I shouldn'...</td>\n",
       "      <td>2007-01-23 19:04:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  tTweetID                                             tTweet  \\\n",
       "119368     5622     28191           trying to figure out what this thing is.   \n",
       "825210    38323    581203  Getting ready to go to the Improv Olympic to s...   \n",
       "1663297  690103   3873613                 Customer support is no fun at all.   \n",
       "1663296  690103   3880013                  I am still doing customer support   \n",
       "1663295  690103   3880323  Bryan is a nice guy cause he thinks I shouldn'...   \n",
       "\n",
       "                 tCreatedAt  \n",
       "119368  2006-09-10 11:07:07  \n",
       "825210  2006-12-02 21:34:25  \n",
       "1663297 2007-01-23 18:07:29  \n",
       "1663296 2007-01-23 19:01:33  \n",
       "1663295 2007-01-23 19:04:58  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tCreatedAt').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552720</th>\n",
       "      <td>22307857</td>\n",
       "      <td>6485532854</td>\n",
       "      <td>NYC at holiday time, can't go wrong. Ate with ...</td>\n",
       "      <td>2009-12-08 21:27:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738094</th>\n",
       "      <td>15676578</td>\n",
       "      <td>6485597908</td>\n",
       "      <td>Spoiler: Find out who won Biggest Loser! http:...</td>\n",
       "      <td>2009-12-08 21:29:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672933</th>\n",
       "      <td>22097952</td>\n",
       "      <td>6485873515</td>\n",
       "      <td>@katelynroseee hahaha. I mean, New York Style ...</td>\n",
       "      <td>2009-12-08 21:39:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108263</th>\n",
       "      <td>34739186</td>\n",
       "      <td>6486280798</td>\n",
       "      <td>WOW! Cardio Barre was AMAZING-I had no idea u ...</td>\n",
       "      <td>2009-12-08 21:54:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108262</th>\n",
       "      <td>34739186</td>\n",
       "      <td>6486831431</td>\n",
       "      <td>Stop tweeting while we're at dinner!!! ;) RT @...</td>\n",
       "      <td>2009-12-08 22:14:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID    tTweetID  \\\n",
       "552720   22307857  6485532854   \n",
       "1738094  15676578  6485597908   \n",
       "1672933  22097952  6485873515   \n",
       "108263   34739186  6486280798   \n",
       "108262   34739186  6486831431   \n",
       "\n",
       "                                                    tTweet          tCreatedAt  \n",
       "552720   NYC at holiday time, can't go wrong. Ate with ... 2009-12-08 21:27:36  \n",
       "1738094  Spoiler: Find out who won Biggest Loser! http:... 2009-12-08 21:29:53  \n",
       "1672933  @katelynroseee hahaha. I mean, New York Style ... 2009-12-08 21:39:27  \n",
       "108263   WOW! Cardio Barre was AMAZING-I had no idea u ... 2009-12-08 21:54:03  \n",
       "108262   Stop tweeting while we're at dinner!!! ;) RT @... 2009-12-08 22:14:24  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_values(by='tCreatedAt').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='UserID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='UserID').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tTweetID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tTweetID').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tTweet').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tTweet').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>14</td>\n",
       "      <td>1004190858</td>\n",
       "      <td>Giving 60 dictionaries to 60 highly energetic ...</td>\n",
       "      <td>2008-11-13 11:55:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>14</td>\n",
       "      <td>4119972522</td>\n",
       "      <td>ound like French summer.</td>\n",
       "      <td>2009-09-20 02:21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>14</td>\n",
       "      <td>3881145051</td>\n",
       "      <td>fireworks blast over Santa Monica scattering s...</td>\n",
       "      <td>2009-09-09 23:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>14</td>\n",
       "      <td>3599227170</td>\n",
       "      <td>today my prototype danced for me. perfect piro...</td>\n",
       "      <td>2009-08-28 03:52:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>14</td>\n",
       "      <td>3324787395</td>\n",
       "      <td>If Kafka gave birth atop the trade center towe...</td>\n",
       "      <td>2009-08-15 02:09:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserID    tTweetID                                             tTweet  \\\n",
       "259      14  1004190858  Giving 60 dictionaries to 60 highly energetic ...   \n",
       "283      14  4119972522                           ound like French summer.   \n",
       "284      14  3881145051  fireworks blast over Santa Monica scattering s...   \n",
       "285      14  3599227170  today my prototype danced for me. perfect piro...   \n",
       "286      14  3324787395  If Kafka gave birth atop the trade center towe...   \n",
       "\n",
       "             tCreatedAt  \n",
       "259 2008-11-13 11:55:58  \n",
       "283 2009-09-20 02:21:31  \n",
       "284 2009-09-09 23:44:42  \n",
       "285 2009-08-28 03:52:22  \n",
       "286 2009-08-15 02:09:23  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tCreatedAt').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tTweetID</th>\n",
       "      <th>tTweet</th>\n",
       "      <th>tCreatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4425852</th>\n",
       "      <td>15342502</td>\n",
       "      <td>10617707268</td>\n",
       "      <td>Bout to nap it up, please DND.</td>\n",
       "      <td>2010-03-17 06:49:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427177</th>\n",
       "      <td>50765154</td>\n",
       "      <td>10617911844</td>\n",
       "      <td>Made it to work ontime! Now I need spmeone to ...</td>\n",
       "      <td>2010-03-17 06:55:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384903</th>\n",
       "      <td>18782786</td>\n",
       "      <td>10618404437</td>\n",
       "      <td>@wizwow, thanks for yet another insightful pos...</td>\n",
       "      <td>2010-03-17 07:10:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119490</th>\n",
       "      <td>26962064</td>\n",
       "      <td>10618517948</td>\n",
       "      <td>@MiszTdott when I pointless text you, you poin...</td>\n",
       "      <td>2010-03-17 07:14:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235010</th>\n",
       "      <td>15458701</td>\n",
       "      <td>10619091335</td>\n",
       "      <td>Preach Jesus Christ first and foremost as a ma...</td>\n",
       "      <td>2010-03-17 07:31:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserID     tTweetID  \\\n",
       "4425852  15342502  10617707268   \n",
       "2427177  50765154  10617911844   \n",
       "1384903  18782786  10618404437   \n",
       "3119490  26962064  10618517948   \n",
       "235010   15458701  10619091335   \n",
       "\n",
       "                                                    tTweet          tCreatedAt  \n",
       "4425852                     Bout to nap it up, please DND. 2010-03-17 06:49:15  \n",
       "2427177  Made it to work ontime! Now I need spmeone to ... 2010-03-17 06:55:50  \n",
       "1384903  @wizwow, thanks for yet another insightful pos... 2010-03-17 07:10:55  \n",
       "3119490  @MiszTdott when I pointless text you, you poin... 2010-03-17 07:14:22  \n",
       "235010   Preach Jesus Christ first and foremost as a ma... 2010-03-17 07:31:11  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='tCreatedAt').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " - Step 4: Write out restructured datasets for future ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE OUT RESTRUCTURED DATA TO CSV:\n",
    "\n",
    "train_df.to_csv('./Data/corrected_training_set_tweets.csv')\n",
    "test_df.to_csv('./Data/corrected_test_set_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CONVERT THE DATE COLUMNS TO DATETIME OBJECTS:\n",
    "\n",
    "claim_df.ClaimDate = pd.to_datetime(claim_df.ClaimDate)\n",
    "policy_df.EnrollDate = pd.to_datetime(policy_df.EnrollDate)\n",
    "policy_df.CancelDate = pd.to_datetime(policy_df.CancelDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 3: Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## BASIC STATISTICS FOR THE CLAIMS DATA:\n",
    "\n",
    "claim_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## THERE WAS ONE NEGATIVE CLAIM:\n",
    "\n",
    "claim_df[claim_df.ClaimedAmount < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## IT SEEMS LIKE THIS WAS A REVERSAL OF A CHARGE ON THE SAME DAY:\n",
    "\n",
    "claim_df[claim_df.PolicyId == 777949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## BASIC STATISTICS FOR THE POLICY DATA:\n",
    "\n",
    "policy_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## VIEW POLICIES THAT DO NOT HAVE AN ASSIGNED MONTHLY PREMIUM:\n",
    "\n",
    "policy_df[policy_df.MonthlyPremium.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHECK THE DATE RANGES TO MAKE SURE THIS IS ALL 2016 DATA:\n",
    "\n",
    "print(\"Earliest Date of Claims\", claim_df.ClaimDate.min())\n",
    "print(\"Latest Date of Claims\", claim_df.ClaimDate.max())\n",
    "print(\"\\nEarliest Date of Policy Enrollment\", policy_df.EnrollDate.min())\n",
    "print(\"Latest Date of Policy Enrollment\", policy_df.EnrollDate.max())\n",
    "print(\"\\nEarliest Date of Policy Cancel\", policy_df.CancelDate.min())\n",
    "print(\"Latest Date of Policy Cancel\", policy_df.CancelDate.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MANY CUSTOMERS ENROLLED LONG BEFORE 2016:  \n",
    "\n",
    "print(\"Number of Policy Holders Enrolled Prior to 2016:\", \n",
    "      policy_df[policy_df.EnrollDate < '2016'].shape[0])\n",
    "policy_df[policy_df.EnrollDate < '2016'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## COUNT OF UNIQUE POLICY ID'S:\n",
    "\n",
    "print(\"Unique Policy ID's:\", policy_df.PolicyId.unique().shape[0])\n",
    "print(\"Number of Duplicated Rows:\", sum(policy_df.duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## COUNT OF UNIQUE POLICY ID'S THAT FILED CLAIMS:\n",
    "\n",
    "print(\"Unique Policy ID's That Filed Claims:\", \n",
    "      claim_df.PolicyId.unique().shape[0])\n",
    "print(\"Number of Duplicated Rows:\", sum(claim_df.duplicated()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key finding:**  \n",
    "  \n",
    "**There are 3,744 claims that have duplicates; resulting in 6,616 rows (4.255%) are duplicates of another.**  \n",
    "  \n",
    "**This would be a pivotal time to reach out to check that these are in-fact valid claims.  Due to this being a homework assignment, I will make the executive decision that these *are* valid claims.  For example, perhaps the animal went to the veterinarian for two vaccines, which resulted in two identical claim amounts on the same day.**  \n",
    "\n",
    "**Please note that this is an assumption, and in the real world I would ask for further clarification prior to proceeding with analyses.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MANY CLAIMS ARE DUPLICATED:\n",
    "\n",
    "print(\"Duplicated Claims Account for\", \n",
    "      claim_df[claim_df.duplicated(keep=False)].shape[0],\n",
    "      \"Rows of the Claims Data.  This is\",\n",
    "      round(claim_df[claim_df.duplicated(keep=False)].shape[0] \n",
    "      / claim_df.shape[0] * 100, 3), \"% of the Claims Data.\")\n",
    "claim_df[claim_df.duplicated(keep=False)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 4: Transform & merge the data to a monthly-per-policy basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ADD A LEVEL TO COLUMN INDEX TO ALIGN WITH THE MONTHLY CLAIMS DATA:\n",
    "\n",
    "# Re-assign DataFrame to another name:\n",
    "reindex_policy = pd.DataFrame(policy_df)\n",
    "\n",
    "# Reset the index level to prevent an error from occurring if \n",
    "# this cell is run more than once:\n",
    "try:\n",
    "    reindex_policy = reindex_policy[list(policy_df.columns.levels[0].values)]\n",
    "except: \n",
    "    reindex_policy = policy_df[list(policy_df.columns.values)]\n",
    "\n",
    "# Add extra level to column index:\n",
    "reindex_policy.columns = pd.MultiIndex.from_arrays([reindex_policy.columns, \n",
    "                    [' '] * len(reindex_policy.columns)])\n",
    "\n",
    "# Print preview of re-indexed policy DataFrame:\n",
    "reindex_policy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PIVOT & MERGE THE TWO DATAFRAMES TO GET A MORE COMPLETE PICTURE OF \n",
    "## CLAIMS BEHAVIOUR, ADDING ADDITION METRICS (FEATURES) FOR MODELLING:\n",
    "\n",
    "# Pivot the claim DataFrame to have one row per policy, & a column\n",
    "# for every month's ClaimedAmount & PaidAmount; if not claim data, \n",
    "# fill as '$0' claim:\n",
    "pivot_df = pd.pivot_table(claim_df,index=claim_df['PolicyId'],\n",
    "               columns=claim_df['ClaimDate'].dt.month,\n",
    "               aggfunc=np.sum, fill_value=0).reset_index()\n",
    "\n",
    "# Merge the Claims and Policy DataFrames together in an 'left' join on PolicyId:\n",
    "wide_df = reindex_policy.join(pivot_df.set_index('PolicyId'))\n",
    "\n",
    "# Fill in missing amounts with zeros:\n",
    "wide_df['ClaimedAmount'] = wide_df.ClaimedAmount.fillna(0)\n",
    "wide_df['PaidAmount'] = wide_df.PaidAmount.fillna(0)\n",
    "\n",
    "# Calculate basic metrics for each policy:\n",
    "wide_df['MeanClaims'] = np.mean(wide_df.ClaimedAmount, axis=1)\n",
    "wide_df['MeanPaid'] = np.mean(wide_df.PaidAmount, axis=1)\n",
    "wide_df['MedianClaims'] = np.median(wide_df.ClaimedAmount, axis=1)\n",
    "wide_df['MedianPaid'] = np.median(wide_df.PaidAmount, axis=1)\n",
    "wide_df['TotalClaims'] = np.sum(wide_df.ClaimedAmount, axis=1)\n",
    "wide_df['TotalPaid'] = np.sum(wide_df.PaidAmount, axis=1)\n",
    "wide_df['TotalDifference'] =  (np.sum(wide_df.ClaimedAmount, axis=1) - \n",
    "                               np.sum(wide_df.PaidAmount, axis=1))\n",
    "wide_df['ProportionCovered'] =  (np.sum(wide_df.PaidAmount, axis=1) / \n",
    "                                    np.sum(wide_df.ClaimedAmount, axis=1))\n",
    "\n",
    "# Since we only have claims for 2016, calculate the number of months &  \n",
    "# paid premiums in 2016 alone:\n",
    "wide_df['Premiums2016'] = (np.where(pd.to_datetime(pd.Series(wide_df['CancelDate'])).dt.year == 2016,\n",
    "         pd.to_datetime(pd.Series(wide_df['CancelDate'])).dt.month, 12) \n",
    "         - np.where(pd.to_datetime(pd.Series(wide_df['EnrollDate'])).dt.year == 2016, \n",
    "         pd.to_datetime(pd.Series(wide_df['EnrollDate'])).dt.month, 0))\n",
    "wide_df['PremiumsPaid2016'] = np.multiply(wide_df.Premiums2016.values, \n",
    "                                       wide_df.MonthlyPremium.iloc[0:, 0].values)\n",
    "wide_df['PremiumVPaid'] = (wide_df.PremiumsPaid2016.values - wide_df.TotalPaid.values)\n",
    "\n",
    "# Use a binary key to mark if the customer is current or canceled at the end of 2016:\n",
    "wide_df['Churned'] = np.where(wide_df.CancelDate.fillna(0) \n",
    "                                       > pd.datetime(2016, 1, 1), 1, 0)\n",
    "\n",
    "# Calculate the total number of months the customer has held a policy:\n",
    "end = pd.to_datetime('2016-12-31')\n",
    "wide_df['PolicyLength'] = (wide_df.CancelDate.fillna(end) - \n",
    "                           wide_df.EnrollDate).astype('timedelta64[M]')\n",
    "\n",
    "# Print a preview of the prepared DataFrame:\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WRITE OUT THE PREPARED DATA FRAME FOR FUTURE REFERENCE:\n",
    "\n",
    "# Condense the columns' MultiIndex for clarification prior to writing out:\n",
    "write_out = wide_df.copy(deep=True)\n",
    "write_out.columns =  [''.join(tuple(map(str, t))) for t in write_out.columns.values]\n",
    "write_out.to_csv('./Data/PreparedData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key finding:**  \n",
    "  \n",
    "**Based on the provided data, using 2016 premiums collected (assuming *no* pro-rating for partial months) & paid claims only, Trupanion made a gross profit of $24,185,900.12!**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DATA FACT == IN THE BLACK FOR 2016:\n",
    "\n",
    "# Calculation of the 2016 total sum of premiums paid to Trupanion minus paid claims:\n",
    "print('$', round(np.sum(wide_df.PremiumVPaid), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key finding:**  \n",
    "  \n",
    "**There are 5 policies missing data on monthly premiums.  I typically would ask for clarification here, but since there are so few I'll make the executive decision.  I believe that these rows should be dropped for a model on paid claims, because none of them had any claims submitted or paid.  However, since 4 out of the 5 rows were canceled policies, I would choose to keep them for a model on cancel predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## LOCATE POLICIES MISSING MONTHLY PREMIUM DATA & CREATE NEW DATAFRAMES FOR USE \n",
    "## IN PAID CLAIMS & CANCELATION MODELING:\n",
    "\n",
    "# Identify the rows with missing data:\n",
    "missing = np.argwhere(np.isnan(wide_df.xs('PremiumVPaid', axis=1, drop_level=True))).ravel()\n",
    "no_premium = wide_df[wide_df.index.isin(missing)] \n",
    "\n",
    "# DataFrame without the 5 rows:\n",
    "paid_df = wide_df[~wide_df.index.isin(no_premium.index)]\n",
    "\n",
    "# DataFrame with 5 missing premiums filled with zeros:\n",
    "no_premium[['MonthlyPremium', 'PremiumsPaid2016', 'PremiumVPaid']] = (\n",
    "    no_premium[['MonthlyPremium', 'PremiumsPaid2016', 'PremiumVPaid']].fillna(0))\n",
    "cancel_df = pd.concat([paid_df, no_premium])\n",
    "\n",
    "# Print the policies with missing premiums:\n",
    "no_premium = wide_df[wide_df.index.isin(missing)] \n",
    "no_premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## THE MOST EXPENSIVE CUSTOMERS:\n",
    "\n",
    "a = paid_df.PremiumVPaid.sort_values()[0:5].index\n",
    "paid_df[paid_df.index.isin(a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Step 5: Visualize the data to help determine appropriate modeling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "plt.plot(np.sum(wide_df, axis=0).ClaimedAmount, label='Claimed Amount')\n",
    "plt.plot(np.sum(wide_df, axis=0).PaidAmount, label='Paid Amount')\n",
    "plt.title('Total Claimed & Paid Amounts in 2016, by Month')\n",
    "plt.xlim(0.9, 12.1)\n",
    "plt.xlabel('Month')\n",
    "plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12], ['January', 'February', \n",
    "            'March', 'April', 'May', 'June', 'July', 'August', \n",
    "            'September', 'October', 'November', 'December'], rotation=45)\n",
    "plt.ylabel('Total Dollars')\n",
    "plt.legend(loc=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "sns.distplot(paid_df.PremiumVPaid.astype(int))\n",
    "plt.title('Distribution of Premiums Collected Minus Paid Claims')\n",
    "plt.xlabel('Premium Collected Minus Paid Claims');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DATA DISTRIBUTION COMPARISONS:\n",
    "\n",
    "plt_format()\n",
    "\n",
    "sns.violinplot(x='Churned', y='MonthlyPremium ', data=write_out, \n",
    "               split=True, inner='quartile', saturation=0.6, \n",
    "               palette={1: \"deepskyblue\", 0: \"mediumpurple\"})\n",
    "plt.title('Monthly Premium Distributions, Separated by Churn Status')\n",
    "plt.xlabel('Churned')\n",
    "plt.ylabel('Monthly Premium, USD')\n",
    "\n",
    "plt.ylim(0, 180);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DATA DISTRIBUTION COMPARISONS:\n",
    "\n",
    "plt_format()\n",
    "\n",
    "sns.violinplot(x='Churned', y='PolicyLength', \n",
    "               data=write_out, split=True, inner='quartile', saturation=0.6, \n",
    "               palette={1: \"deepskyblue\", 0: \"mediumpurple\"})\n",
    "plt.title('Policy Length Distributions, Separated by Churn Status')\n",
    "plt.xlabel('Churned')\n",
    "plt.ylabel('Policy Length, in Months')\n",
    "\n",
    "plt.ylim(-10, 210);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DATA DISTRIBUTION COMPARISONS:\n",
    "\n",
    "plt_format()\n",
    "\n",
    "sns.violinplot(x='Churned', y='TotalPaid', \n",
    "               data=write_out, split=True, inner='quartile', saturation=0.6, \n",
    "               palette={1: \"deepskyblue\", 0: \"mediumpurple\"})\n",
    "plt.title('Total Paid Distributions, Separated by Churn Status')\n",
    "plt.xlabel('Churned')\n",
    "plt.ylabel('Total Paid, USD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "plt.plot(paid_df.PolicyLength, paid_df.MonthlyPremium, '.')\n",
    "plt.title('Policy Length vs. Monthly Premium')\n",
    "plt.xlabel('Policy Length, in Months')\n",
    "plt.ylabel('Monthly Premium, in Dollars');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "plt.plot(paid_df.EnrollDate, paid_df.MeanPaid, '.')\n",
    "plt.title('Enrollment Date vs. Average Paid Claim Amount')\n",
    "plt.xlabel('Enrollment Date')\n",
    "plt.ylabel('Mean Paid Claim Amount, in Dollars');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "sns.distplot(paid_df.PolicyLength.astype(int))\n",
    "plt.title('Policy Length Distribution')\n",
    "plt.xlabel('Policy Length, in Months');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "---  \n",
    "  \n",
    "---  \n",
    "  \n",
    "  \n",
    "## Model: Predicting Cancellation Probabilities \n",
    "  \n",
    " - First, run through a trial model to get an idea of how model will perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DEFINE MODEL INPUT FEATURES & OUTPUT:\n",
    "\n",
    "df = cancel_df.copy(deep=True)\n",
    "\n",
    "input_features = ['ClaimedAmount', 'MonthlyPremium', 'PaidAmount', \n",
    "                  'MeanClaims', 'MeanPaid', 'MedianClaims', \n",
    "                  'MedianPaid', 'TotalClaims', 'TotalPaid', \n",
    "                  'TotalDifference', 'Premiums2016', 'PremiumsPaid2016', \n",
    "                  'PremiumVPaid', 'PolicyLength']\n",
    "output_feature = 'Churned'\n",
    "\n",
    "X = df[input_features]\n",
    "y = df[output_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "sns.heatmap(pd.concat([pd.DataFrame(X), y], axis=1).corr())\n",
    "plt.title('Heatmap of Data Feature Correlations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST MODELING:\n",
    "\n",
    "# Split into training & test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "# Scale the data to a mean of '0' and standard deviation of '1'\n",
    "# Scaling the test data on the training set:\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "      \n",
    "# Initialize a classifier:\n",
    "clf = RF(n_estimators=10, criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict classes:\n",
    "y_pred = clf.predict(X_test)\n",
    "# Predict probabilities:\n",
    "y_prob = clf.predict_proba(X_test)\n",
    "    \n",
    "# Print the accuracy:\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"  Accuracy: \", accuracy*100, '%\\n')\n",
    "\n",
    "print('  Model Statistics:')\n",
    "confusion_matrices = ConfusionMatrix(y_test, y_pred)\n",
    "confusion_matrices.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "confusion_matrices.plot(backend='seaborn', annot=True, fmt=\".0f\")\n",
    "plt.title('Confusion Matrix of Cancellation Predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## EVALUATE PROBABILITY PREDICTIONS:\n",
    "\n",
    "# Number of times a predicted probability is assigned to an observation:\n",
    "counts = pd.value_counts(y_prob[:, 1])\n",
    "is_churn = y_test == 1\n",
    "\n",
    "# Calculate true probabilities:\n",
    "true_prob = {}\n",
    "for prob in counts.index:\n",
    "    true_prob[prob] = np.mean(is_churn[y_prob[:, 1] == prob])\n",
    "    true_prob = pd.Series(true_prob)\n",
    "\n",
    "# Reshape & rename:\n",
    "counts = pd.concat([counts, true_prob], axis=1).reset_index()\n",
    "counts.columns = ['pred_prob', 'count', 'true_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "baseline = np.mean(is_churn)\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10), \n",
    "         c=\"#95a5a6\", linewidth=3, alpha=0.8, label='Ideal Predection Line')\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(baseline, baseline, 10), \n",
    "         c=\"#3498db\", linewidth=3, alpha=0.8, label='Mean Probability of Churn')\n",
    "plt.scatter(data=counts, x='pred_prob', y='true_prob', s='count', \n",
    "            marker='o', label=None, alpha=0.7, c=\"#9b59b6\")\n",
    "plt.title(\"Random Forest Model Outcomes\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Relative Frequency of Outcome\")\n",
    "plt.xlim(-0.05,  1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_format()\n",
    "\n",
    "conf_mat = pd.DataFrame(\n",
    "    confusion_matrix(y_test.values, y_pred), \n",
    "    columns=[\"Predicted False\", \"Predicted True\"], \n",
    "    index=[\"Actual False\", \"Actual True\"]\n",
    ")\n",
    "display(conf_mat)\n",
    "\n",
    "# Calculate the false positives & true positives for all thresholds of the classification\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_prob[:, 1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, color='deepskyblue', linewidth=3)\n",
    "plt.plot([0, 1], [0, 1], '--', color='mediumpurple', linewidth=3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 18))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "df_f = pd.DataFrame(clf.feature_importances_, columns=[\"Importance\"])\n",
    "df_f[\"Labels\"] = df[input_features].columns\n",
    "df_f.sort_values(\"Importance\", inplace=True, ascending=False)\n",
    "display(df_f.head(5))\n",
    "\n",
    "index = np.arange(len(clf.feature_importances_))\n",
    "bar_width = 0.7\n",
    "rects = plt.barh(index , df_f[\"Importance\"], bar_width, alpha=0.4, color='b', label='Main')\n",
    "plt.yticks(index, df_f[\"Labels\"])\n",
    "plt.title('Proportion of Importance for each Model Input Feature')\n",
    "plt.xlabel('Importance, Proportion')\n",
    "plt.ylabel('Model Input Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PREVIEW CHURN PROBABILITIES:\n",
    "\n",
    "pd.DataFrame(y_prob).iloc[:, 1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "- Final cancellation prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST MODELING; TRAIN FINAL MODEL WITH OUTPUT:\n",
    "\n",
    "# Scale the data to a mean of '0' and standard deviation of '1':\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "      \n",
    "# Initialize a classifier:\n",
    "clf = RF(n_estimators=4, criterion='entropy', random_state=None)\n",
    "clf.fit(X, y)\n",
    "# Predict classes:\n",
    "y_pred = clf.predict(X)\n",
    "# Predict probabilities:\n",
    "y_prob = clf.predict_proba(X)\n",
    "    \n",
    "# Print the accuracy:\n",
    "accuracy = clf.score(X, y)\n",
    "print(\"  Accuracy: \", accuracy*100, '%\\n')\n",
    "\n",
    "print('  Model Statistics:')\n",
    "confusion_matrices = ConfusionMatrix(y, y_pred)\n",
    "confusion_matrices.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## EVALUATE PROBABILITY PREDICTIONS:\n",
    "\n",
    "# Number of times a predicted probability is assigned to an observation:\n",
    "counts = pd.value_counts(y_prob[:, 1])\n",
    "is_churn = y == 1\n",
    "\n",
    "# Calculate true probabilities:\n",
    "true_prob = {}\n",
    "for prob in counts.index:\n",
    "    true_prob[prob] = np.mean(is_churn[y_prob[:, 1] == prob])\n",
    "    true_prob = pd.Series(true_prob)\n",
    "\n",
    "# Reshape & rename:\n",
    "counts = pd.concat([counts, true_prob], axis=1).reset_index()\n",
    "counts.columns = ['pred_prob', 'count', 'true_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PLOT PREDICTION COUNTS:\n",
    "\n",
    "plt_format()\n",
    "\n",
    "baseline = np.mean(is_churn)\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10), \n",
    "         c=\"#95a5a6\", linewidth=3, alpha=0.8, label='Ideal Predection Line')\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(baseline, baseline, 10), \n",
    "         c=\"#3498db\", linewidth=3, alpha=0.8, label='Mean Probability of Churn')\n",
    "plt.scatter(data=counts, x='pred_prob', y='true_prob', s='count', \n",
    "            marker='o', label=None, alpha=0.7, c=\"#9b59b6\")\n",
    "plt.title(\"Random Forest Model Outcomes\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Relative Frequency of Outcome\")\n",
    "plt.xlim(-0.05,  1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WRITE OUT CANCELLATION PROBABILITIES:\n",
    "\n",
    "cancel_probs = pd.DataFrame(y_prob).iloc[:, 1]\n",
    "cancel_probs = pd.concat([df.PolicyId, cancel_probs], axis=1)\n",
    "cancel_probs.columns = ['PolicyId', 'CancelProb']\n",
    "cancel_probs.to_csv('./Data/CancellationProbabilities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "  \n",
    "---  \n",
    "  \n",
    "### In conclusion, \n",
    "\n",
    "#### Thank you very much for considering me for the Data Scientist position at Trupanion!  I know your time is valuable, and I hope that you find my thorough answers helpful in assessing my mental processes.  I look forward to hearing from you soon!\n",
    "\n",
    "**Regards,**  \n",
    "**Heather M. Steich, M.S.**\n",
    "\n",
    "Contact Info:\n",
    "  - Phone: 925-321-3997  \n",
    "  - Email: [hms_945@yahoo.com](mailto:hms_945@yahoo.com)  \n",
    "  - LinkedIn: [HeatherSteich](https://www.linkedin.com/in/heathersteich)  \n",
    "  - Github: [hsteich](https://www.github.com/hsteich)  \n",
    "  - YouTube Channel: [DataScienceBrushUp](https://www.youtube.com/channel/UCPxg-VShHJ19t3IwnS1mMMQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
