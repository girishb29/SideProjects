{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"https://cdn.mantelligence.com/wp-content/uploads/2017/11/Best-Beer-of-the-Month-Club-In-Depth-Beer-Club-Reviews.jpg\", width= \"400\">  \n",
    "  \n",
    "\n",
    "# Decision Tree Regression & Beer Reviews  \n",
    "  \n",
    "\n",
    "---  \n",
    "  \n",
    "**By: Heather M. Steich, M.S.**  \n",
    "**Date: March 30$^{th}$, 2018**  \n",
    "**Written in: Python 3.4.5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.5 | packaged by conda-forge | (default, Sep  8 2016, 14:36:52) [MSC v.1600 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Instructions\n",
    " \n",
    "The following dataset consists of $1.5^+ million$ beer reviews from [beeradvocate.com](https://www.beeradvocate.com/): \n",
    " - [https://s3.amazonaws.com/demo- datasets/beer_reviews.tar.gz](https://s3.amazonaws.com/demo- datasets/beer_reviews.tar.gz)  \n",
    "  \n",
    "Document your thought process as you answer these questions. Include any plots used to support your answers and provide the code, either packaged with the analysis as a markdown or notebook file or separately in a code file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "  \n",
    "# Initial Setup  \n",
    "  \n",
    "  \n",
    " - Load analytic libraries  \n",
    " - Establish plot formatting  \n",
    " - Load the data  \n",
    "  \n",
    "\n",
    "This submission was created with a Jupyter Notebook.  There are no special instructions for running the code, as long as one has all the required libraries installed.  All the utilized Python libraries and visualization templates are included in the following code block; once run successfully, the rest of the notebook should run and compile without difficulty.  Since these libraries are all open source, I've included links to the source documentation for each below.  \n",
    "  \n",
    "\n",
    " - Data wrangling & processing:  \n",
    "    - [NumPy](http://www.numpy.org/)  \n",
    "    - [pandas](https://pandas.pydata.org/pandas-docs/stable/)  \n",
    "  \n",
    "\n",
    " - Analysis outcome measurements:  \n",
    "    - [DecisionTreeRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "    - [uniform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html)  \n",
    "    - [Mean squared error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)  \n",
    "\n",
    "\n",
    " - Plotting:  \n",
    "    - [matplotlib](https://matplotlib.org/contents.html)  \n",
    "    - [matplotlib.pyplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)\n",
    "    - [seaborn](https://seaborn.pydata.org/)   \n",
    "    - [Annotations guide](https://matplotlib.org/users/annotations_guide.html)  \n",
    "  \n",
    "\n",
    " - Remove warning messages:  \n",
    "    - [warnings](https://docs.python.org/3.1/library/warnings.html)  \n",
    "    - [warnings.filterwarnings('ignore')](https://docs.python.org/3.1/library/warnings.html#warnings.filterwarnings)  \n",
    "  \n",
    "\n",
    "Although I did not specifically reference on each plot, I did utilize [ColorBrewer2](http://colorbrewer2.org/) on several occasions when selecting colors from color palates that work well together and are color blind friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOAD LIBRARIES ###\n",
    "\n",
    "\n",
    "# Data wrangling & processing: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Analysis outcome measurements:  \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Plotting:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid.anchored_artists import AnchoredText\n",
    "\n",
    "\n",
    "# Remove warning messages:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ESTABLISH PLOT FORMATTING ###\n",
    "\n",
    "\n",
    "#mpl.rcdefaults()  # Resets plot defaults\n",
    "\n",
    "def plt_format():\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (16, 10)\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['axes.labelcolor'] = 'black'\n",
    "    plt.rcParams['axes.labelsize'] = 20\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titlesize'] = 32\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['legend.fontsize'] = 16\n",
    "    plt.rcParams['legend.markerscale'] = 4\n",
    "    plt.rcParams['text.color'] = 'black'\n",
    "    plt.rcParams['xtick.labelsize'] = 20\n",
    "    plt.rcParams['ytick.labelsize'] = 20\n",
    "    plt.rcParams['legend.fontsize'] = 16\n",
    "    plt.rcParams['legend.frameon'] = False\n",
    "    plt.rcParams['axes.linewidth'] = 1\n",
    "\n",
    "#plt.rcParams.keys()  # Available rcParams\n",
    "plt_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./beer_reviews/beer_reviews.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e59385498108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m### READ IN THE DATA ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./beer_reviews/beer_reviews.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hms_9\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hms_9\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hms_9\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hms_9\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\hms_9\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./beer_reviews/beer_reviews.csv' does not exist"
     ]
    }
   ],
   "source": [
    "### READ IN THE DATA ###  \n",
    "\n",
    "df = pd.read_csv('./beer_reviews/beer_reviews.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "  \n",
    "# Data Quality Evaluation & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DATASET DIMENSIONS ###\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DATA TYPES ###\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "The columns `brewery_id`, `review_time` and `beer_beerid` were parsed as integers, but that is not the correct type.  \n",
    "  \n",
    "The `review_time` column is actually a datetime object but formatted in UNIX time.  This is simple to convert, and the purpose would be to make it more human readable as well as being able to utilize the datetime functionality.  That opens the potential for time series analyses and more intuitive visualizations.  \n",
    "  \n",
    "The ID number columns (`brewery_id` and `beer_beerid`) are neither integers nor ordinal.  Specifically, they should be categorial type, dummy variables or strings.  However, since comparison statements are so much slower on strings than integers, and because the purpose of this exercise does not include modeling, I will leave them as integer types to speed up the code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CONVERT DATA TYPES ###\n",
    "\n",
    "# Converting UNIX time into more human readable datetime objects:\n",
    "df['review_time'] = pd.to_datetime(df['review_time'], unit='s')\n",
    "print('Updated `review_time` data type: ', df.review_time.dtype, '\\n')\n",
    "\n",
    "# An example of the time difference between string & integer operations:\n",
    "%timeit df.brewery_id[df.brewery_id.astype(str) == '10325']\n",
    "%timeit df.brewery_id[df.brewery_id == 10325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CHECK FOR MISSING DATA ###\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "Thankfully, this is overall a very complete, with minimal missing values.  The columns `brewery_name`, `review_profilename` and `beer_abv` contain a small percentage of missing numbers, with `beer_abv` being the most significant, at just over $4.27 \\%$ (calculations below).\n",
    "  \n",
    "Even though the missing data isn't a high percentage, I investigated if there is a way to reverse-engineer these missing points.  \n",
    "\n",
    " - I checked corresponding `brewery_id`s for the missing `brewery_name`s, but these IDs were unique to the missing names.  Alternatively, I also looked for matching `beer_beerid`s and / `beer-name`s.  Some of the `beer_name` features did indicate that the `brewery_name` was incorrect and to reference values for another brewery.  Due to time constraints, I did not fully validate these cross-references or impute the missing names.  \n",
    "  \n",
    "\n",
    " - There wasn't an obvious connection between `review_profilename` and other features, except perhaps `review_time`, but investigating this was beyond the scope of this exercise.  \n",
    "  \n",
    "\n",
    " - The `beer_abv` feature had the most significant amount of missing data.  There were some ways to cross reference the `beer_abv` to unique `beer_beerid`s, but only for $25$ of the $67,785$ values, so I did not impute them.  There were several matches on unique `beer_name`s, but after some sorting and filtering by `brewery_name`, there was no obvious trend to map the unique `brewery_name` + `beer_name` combinations to the missing `beer_abv` values.  It seems that several of the `beer_name` values are used by several breweries (hence the difference in count between `beer_name` and `beer_beerid` counts).  After exploring a few other options, I abandoned the idea of imputing these values simply due to time and scope parameters without the promise in much \"lift\" in my answer accuracy for this assignment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PROPORTION OF MISSING DATA ###\n",
    "\n",
    "print('Percentage of `brewery_name` values that are missing: ', \n",
    "      '{:.2e}'.format((df.brewery_name.isnull().sum() / df.shape[0]) * 100) + ' %')\n",
    "print('Percentage of `review_profilename` values that are missing: ', \n",
    "      '{:.2e}'.format((df.review_profilename.isnull().sum() / df.shape[0]) * 100) + ' %')\n",
    "print('Percentage of `beer_abv` values that are missing: ', \n",
    "      '{:.2f}'.format((df.beer_abv.isnull().sum() / df.shape[0]) * 100) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CHECK VALUE UNIQUENESS ###\n",
    "\n",
    "df.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "Since the columns with review scores are all floating-point numbers, this isn't as telling as when the values were integers or categorical variables.  However, what this does reveal is that there are no unique indicators in this dataset, except for the index.  In cases like this, I always like to rule out duplicated rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CHECK FOR DUPLICATED ENTRIES ### \n",
    "\n",
    "print('Number of completely duplicated rows: ', df.duplicated().sum())\n",
    "print('Number of duplicated rows, if only the date is ignored: ', \n",
    "      df.duplicated(subset=df.columns[df.columns != 'review_time']).sum())\n",
    "\n",
    "# Drop duplicated rows in-place, keeping the last instance:\n",
    "df.drop_duplicates(subset=df.columns[df.columns != 'review_time'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "There are some repeats from people who reviewed the same beer with the exact same ratings but at different time markers.  These duplications do not change the ratings of the beers, but they do skew the number of ratings per beer.  Therefore, I will eliminate these rows from the data.  There are various other ways to handle this (marking them as separate, looking for other dimensions for repeats, etc.), but due to the breadth of this assignment, I'll just stick to dropping them and moving on.  I'm also keeping just the last occurrence of the duplicate so that I have a record of each person's most recent activity, in case that is relevant for a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PRINT DESCRIPTIVE STATISTICS FOR EACH NUMERIS FEATURE ###\n",
    "\n",
    "df.describe().loc[:, 'review_overall': 'beer_abv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "  \n",
    "# Data Questions \n",
    "  \n",
    "## 1. Which brewery produces the strongest beers by ABV%?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CHECK THE ABV PERCENTAGE AVERAGES ### \n",
    "\n",
    "print('Mean ABV, by `brewery_id`: ', '{:.2f}'.format(df.groupby(['brewery_id'])['beer_abv'].mean().mean()), '%')\n",
    "print('Mean ABV, by `brewery_id`: ', '{:.2f}'.format(df.groupby(['brewery_name'])['beer_abv'].mean().mean()), '%')\n",
    "print('Median ABV, by `brewery_name`: ', '{:.2f}'.format(df.groupby(['brewery_id'])['beer_abv'].median().median()), '%')\n",
    "print('Median ABV, by `brewery_name`: ', '{:.2f}'.format(df.groupby(['brewery_name'])['beer_abv'].median().median()), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### PLOT ABV BY BEER STYLE ###\n",
    "\n",
    "# Drop `beer_abv` rows containing null values:\n",
    "no_nas = df[['beer_style', 'beer_abv']].dropna()\n",
    "\n",
    "sns.boxplot(no_nas.beer_style, no_nas.beer_abv)\n",
    "plt.title('Beer Alcohol by Volume Percentage by Beer Style')\n",
    "plt.xlabel('Beer Style')\n",
    "plt.xticks(rotation=90, fontsize=9)\n",
    "plt.ylabel('Alcohol by Volume, by %');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### LOCATE THE STRONGEST BEERS ###\n",
    "\n",
    "breweries = [['brewery_id'], ['brewery_name'], ['brewery_id', 'brewery_name']]\n",
    "measure = ['Mean  ', 'Median', 'Total ']\n",
    "\n",
    "for b in breweries:\n",
    "    for i in range(len(measure)):\n",
    "        m = measure[i]\n",
    "        if i == 0:\n",
    "            abv_df = df.groupby(b)['beer_abv'].mean().reset_index()   \n",
    "        elif i == 1:\n",
    "            abv_df = df.groupby(b)['beer_abv'].median().reset_index()\n",
    "        elif i == 2: \n",
    "            abv_df = df.groupby(b)['beer_abv'].max().reset_index()\n",
    "            \n",
    "        \n",
    "        title = abv_df[abv_df.beer_abv == abv_df.beer_abv.max()].iloc[0, 0]\n",
    "        val = abv_df[abv_df.beer_abv == abv_df.beer_abv.max()].iloc[0, 1]\n",
    "        if breweries.index(b) <= 1:\n",
    "            print('Maximum %s ABV by %s = %s is: %s' % (m, b, title, '{:.2f}'.format(val)), '%')\n",
    "        else: \n",
    "            val2 = abv_df[abv_df.beer_abv == abv_df.beer_abv.max()].iloc[0, 2]\n",
    "            print('Maximum %s ABV by %s = %s, %s is: %s' % (m, b, title, val, '{:.2f}'.format(val2)), '%')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "Breaking down the question:  \n",
    "  \n",
    " - \"Which brewery\" could refer to `brewery_id` **or** `brewery_name`.\n",
    " - \"The strongest **beer*s***\" implies that I'm not just looking for the very strongest beer but rather which brewery has the portfolio with the strongest beers in total or on average.  \n",
    " - Average could be interpreted as mean or median.  \n",
    " - \"Beers\" are defined by `beer_name` and `beer_beerid`; there are over $9,000$ more than ID numbers than names for the beers.  However, for this problem, the actual beers do not have to be specified.  \n",
    "\n",
    "By performing a `groupby` function, this removes the granularity of the individual reviews, which is what we need to do to answer this question.  \n",
    "  \n",
    "Despite the mis-match between unique `brewery_id` and `brewery_name` counts, all the groups matched the same `brewery_id` to `brewery_name`, as one would expect if the ID numbers were unique to each name.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:   \n",
    "  \n",
    "> - The `brewery_id` and `brewery_name` with the highest **mean beer portfolio** is:  \n",
    ">    - `brewery_id` = 6513\n",
    ">    - `brewery_name` = Schorschbräu\n",
    ">    - *Mean* `beer_abv` = 19.23 % (rounded)\n",
    "  \n",
    "\n",
    "> - The `brewery_id` and `brewery_name` with the highest **median beer portfolio** is:  \n",
    ">    - `brewery_id` = 14060\n",
    ">    - `brewery_name` = Shoes Brewery\n",
    ">    - *Median* `beer_abv` = 15.20 % (rounded)  \n",
    "  \n",
    "\n",
    "> - The `brewery_id` and `brewery_name` with the highest **ABV beer of all** is:  \n",
    ">    - `brewery_id` = 6513\n",
    ">    - `brewery_name` = Schorschbräu\n",
    ">    - *Maximum* `beer_abv` = 57.70 % (rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "    \n",
    "## 2. If you had to pick 3 beers to recommend using only this data, which would you pick?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BEER REVIEW COUNT STATISTICS ### \n",
    "\n",
    "print('Descriptive Statistics for Beer ID Review Counts:')\n",
    "print(df.beer_beerid.value_counts().describe())\n",
    "print('Number of Beer IDs with at Least 5 Reviews: ', \n",
    "      len(df.beer_beerid.value_counts()[df.beer_beerid.value_counts() >= 5]), '\\n')\n",
    "      \n",
    "print('Descriptive Statistics for Beer Name Review Counts:')\n",
    "print(df.beer_name.value_counts().describe())\n",
    "print('Number of Beer Names with at Least 5 Reviews: ', \n",
    "      len(df.beer_name.value_counts()[df.beer_name.value_counts() >= 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PLOT NUMBER OF REVIEWS FOR EACH BEER ###\n",
    "\n",
    "# Use pre-specified plotting parameters:\n",
    "plt_format()\n",
    "\n",
    "sns.distplot(np.log(df.beer_beerid.value_counts()), color='#67a9cf', \n",
    "             norm_hist=False, kde=False, label='Beer ID')\n",
    "sns.distplot(np.log(df.beer_name.value_counts()), color='#ef8a62', \n",
    "             norm_hist=False, kde=False, label='Beer Name')\n",
    "plt.title('Log Total Beer Reviews by Frequency Count')\n",
    "plt.xlabel('Log Number of Reviews')\n",
    "plt.ylabel('Frequency Count')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PLOT NUMBER OF REVIEWS FOR EACH BEER ###\n",
    "\n",
    "# Use pre-specified plotting parameters:\n",
    "plt_format()\n",
    "\n",
    "sns.distplot(np.log(df.beer_beerid.value_counts()[df.beer_beerid.value_counts() >= 5]), color='#67a9cf', \n",
    "             norm_hist=False, kde=False, label='Beer ID')\n",
    "sns.distplot(np.log(df.beer_name.value_counts()[df.beer_name.value_counts() >= 5]), color='#ef8a62', \n",
    "             norm_hist=False, kde=False, label='Beer Name')\n",
    "plt.title('Log Total Beer Reviews by Frequency Count\\nExcluding Beers with < 5 Reviews')\n",
    "plt.xlabel('Log Number of Reviews\\nExcluding Beers with < 5 Reviews')\n",
    "plt.ylabel('Frequency Count')\n",
    "plt.ylim(0, 2600)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "\n",
    "Some beers have very few reviews.  From a practicality standpoint, perhaps these beers were a limited time or quantity release, only available to small populations, unfairly priced, recalled, poorly marketed, or other reason why the reviews counts are low.  That doesn't necessarily make them bad beers, but we simply do not have enough data points about these beers to draw statistically significant conclusions about them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### REMOVE BEERS WITH LESS THAN 5 REVIEWS FROM DATAFRAME ###\n",
    "\n",
    "# Group the data by review counts:\n",
    "rev_counts = df.groupby(['beer_name'])['beer_beerid'].value_counts()\n",
    "rev_counts = pd.DataFrame(rev_counts[rev_counts >= 5])\n",
    "rev_counts.columns = ['counts']\n",
    "\n",
    "# Define a new, limited DataFrame:\n",
    "beer_df = df[df.beer_beerid.isin(rev_counts.reset_index().beer_beerid.values)]\n",
    "print('Number of unique beer ID values in the limited dataset: ', \n",
    "      beer_df.beer_beerid.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### FIND THE BEERS WITH ALL 100% RATINGS & THE MOST NUMBER OF REVIEWS ###\n",
    "\n",
    "# Localize beers that have all '5.0' ratings across the board:\n",
    "highest_ratings = beer_df[(beer_df['review_overall'] == 5.0) & \n",
    "                          (beer_df['review_aroma'] == 5.0) & \n",
    "                          (beer_df['review_appearance'] == 5.0) & \n",
    "                          (beer_df['review_palate'] == 5.0) & \n",
    "                          (beer_df['review_taste'] == 5.0)]\n",
    "\n",
    "# Group this data subset by `beer_name` & count how many times each beer \n",
    "# received 100% scores:\n",
    "recs = pd.DataFrame(highest_ratings.groupby(['brewery_id', 'brewery_name', 'beer_name'])[\n",
    "    'beer_beerid'].value_counts().sort_values(ascending=False))\n",
    "recs.columns = ['100%_review_count']\n",
    "recs = recs.reset_index()\n",
    "\n",
    "# Extract the top 3 beers:\n",
    "recs.iloc[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**  \n",
    "  \n",
    "> My top three recommendations would be:  \n",
    "  \n",
    "> 1. ***Pliny The Elder***, **by Russian River Brewing Company**  \n",
    "  \n",
    "> 2. ***Trappist Westvleteren 12***, **by Brouwerij Westvleteren (Sint-Sixtusabdij van Westvleteren) Brewery**  \n",
    "  \n",
    "> 3. ***Founders KBS (Kentucky Breakfast Stout)***, **by Founders Brewing Company**  \n",
    "  \n",
    "\n",
    "**EXPLANATION:**  \n",
    "  \n",
    "> Since all I am given is this dataset, I don't know who I am recommending the beers to.  For example, if it were based on *my* taste, I may think of my top three beer choices and check if they are in the dataset or not.  For the record, *Pliny the Elder* is a beer I really enjoy!  Of course, that isn't a very scientific way to go about it.  \n",
    "  \n",
    "> Also, if I knew who I was recommending to, and they already told me similar beers that they've enjoyed in the past, I could find search this dataset for beers in the data set that have a similar type, ABV content and good reviews.  \n",
    "  \n",
    "> Therefore, I am made an assumption that beers I should recommend should be based off of beers that others would recommend.  To define this, I am separating the beers that received $5.0$ rankings for *all* review factors, counting how *many* reviews of each beer fit that criteria, and recommending the top three beers from that list.  No, that isn't just a hunch I came up with; I'm basing that decision off of concepts from the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) and the [Law of Large Numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers).  I won't belabor the subjects here but will share a general overview.  \n",
    "  \n",
    "> The Central Limit Theorem allows one to assume that a good, representative sample will behave similarly to the entire population.  Yes, I am making a generous assumption that these $1.5^+ million$ reviews are representative of the entire beer drinking population.  This is an oversimplification because some of the [top *selling* beers in the U.S.](https://www.statista.com/statistics/188723/top-domestic-beer-brands-in-the-united-states/) are not very highly rated (see totals below).  Barring all that, I'm just going to go off the data in this table and assume that it is representative of the population, and the person(s) I am recommending too are also representative of the population.  \n",
    "  \n",
    "> The Law of Large Numbers gives credit that the more times an observation occurs, the more likely it is to occur again.  For this example, I'm using the beers with the highest counts of $100%$ ratings across the board.  Sure, a beer might get all high scores once or twice by a few fans, but it is less likely to continue the trend unless there are more and more instances of it happening.  That's why I chose the beers with the highest perfect number of review counts.  Here again, I'm assuming on \"big;\" is $110$ to $155$ reviews enough to be considered \"big?\"  Perhaps not, but this is the data I have to work with.  \n",
    "  \n",
    "\n",
    "**ALTERNATE APPROACHES:**  \n",
    "  \n",
    "> Of course, there are many ways I could have attacked this problem, but due to the breadth and importance of this assignment, I stuck to a relatively straightforward method.  I'll detail some other ideas below I had but didn't have time to code out solutions to.  \n",
    "  \n",
    "> - Trends by reviewer  \n",
    ">    - Just as I skimmed off the beers with few reviews, it would likely be a good idea to remove reviews from reviewers who's `review_profilename` appears under a certain threshold.  \n",
    ">    - Some people are inherently more positive or negative than others when responding to satisfaction rankings / surveys ([source](https://www.isixsigma.com/methodology/voc-customer-focus/how-to-avoid-the-evils-within-customer-satisfaction-surveys/)).  I would like to look for these bias trends in the `review_profilename` dimension to see if other reviews need to be eliminated.  \n",
    "  \n",
    "\n",
    "> - Trends over time\n",
    ">    - Many products are subject to a ['tipping point'](https://en.wikipedia.org/wiki/The_Tipping_Point) or 'coolness factor' over time.  It would be good to investigate if such trends show up over time in the beer data.  \n",
    ">    - Is there a seasonality to this data?  If so, perhaps the beers I recommend today would relate to the season.  For example, maybe crisp, light beers are more popular in the summer while heavier, higher alcohol content beers are more popular in the winter months.  *As an aside*: it could be interesting to look at this across different geographies to see if location and or temperature trends play a role in this as well, but that data is not available in this dataset.  \n",
    "  \n",
    "\n",
    "> - Sophisticated Recommendation Systems  \n",
    ">    - There is plenty of research and company examples to prove the power of Recommender Systems.  A consideration here is how much time and effort are worth investing in this project algorithm?  Do we have enough data to generate a good, reliable system?  Are we going to implement this in some way to capture data on the quality of our recommendations and create a feedback loop to continuously train, strengthen and personalize the System's learning for the user (in this case, the beer connoisseur) at hand?    \n",
    ">    - I would want to do some research into similar industries (such as wine, hard spirits or soda) who may have already invested a great deal of time and money into these Systems.  It's always good to learn from other people's successes and failures before trying to recreate the wheel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beers = ['Bud Light', 'Coors Light', 'Miller Light', 'Budweiser', \n",
    "         'Michelob Ultra Light']\n",
    "print('Number of 5.0 reviews for:')\n",
    "for b in beers:\n",
    "    print('   %s =  ' % b, \n",
    "          recs[recs.beer_name.str.contains(b, case=False)\n",
    "              ].brewery_name.value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "    \n",
    "## 3. Which of the factors (aroma, taste, appearance, palette) are most important in determining the overall quality of a beer?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "I am utilizing the limited `beer_df` dataset here, only considering beers with five or more reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHECK FEATURE CORRELATIONS ###\n",
    "\n",
    "# Name the potential factors: \n",
    "factors = ['review_overall', 'review_aroma', 'review_appearance', \n",
    "           'beer_style', 'review_palate', 'review_taste', \n",
    "           'beer_name', 'beer_abv', 'beer_name']\n",
    "\n",
    "# Generate a mask to hide the duplicated values in the upper triangle:\n",
    "mask = np.zeros_like(beer_df[factors].corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Draw the heatmap with mask:\n",
    "sns.heatmap(beer_df[factors].corr(), mask=mask, cmap='BrBG')\n",
    "plt.title('Feature Correlations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "  \n",
    "I also tested the linear correlations on the grouped beer names by taking both the mean and median values for `review_overall` values and merging that back onto the `beer_df` dataset.  The purpose of that was to eliminate the potential \"watering down\" effect of beers with many reviews and diverse ratings.  The mean calculation helps to center the review, while the median calculation is more resistant to outliers.  \n",
    "  \n",
    "However, when I tested these additional features on the correlation matrix, it revealed the same features being most important, but the correlations were much weaker.  To avoid confusion and aide in visual interpretation, I've only included main features here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### MODEL FEATURE IMPORTANCE ###\n",
    "\n",
    "# Define model input & output features:\n",
    "factors = ['review_aroma', 'review_appearance', 'review_palate', \n",
    "           'review_taste', 'beer_abv', 'review_overall']\n",
    "inputs = beer_df[factors].dropna()\n",
    "X = inputs.iloc[:, :-1]\n",
    "y = inputs.iloc[:, -1].values\n",
    "\n",
    "# Train Decision Tree Regressor model & plot feature importances:\n",
    "regr = DecisionTreeRegressor().fit(X, y)\n",
    "sns.barplot(x=X.columns.values, y=(regr.feature_importances_),\n",
    "            palette='BrBG')\n",
    "plt.title('Decision Tree Input Feature Importance')\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Model Feature Importance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSWER:   \n",
    "  \n",
    "> From a linear correlation perspective:  \n",
    "  \n",
    "> - The strongest **positive correlation** to `review_overall` is `review_taste`.\n",
    "  \n",
    "\n",
    "> - The strongest **negative correlation** to `review_overall` is `beer_abv`. \n",
    "  \n",
    "\n",
    "> - The strongest **overall correlation** to `review_overall` is `beer_abv`.\n",
    "  \n",
    "\n",
    "> - The strongest **overall correlation *of the factors in the list*** to `review_overall` is `review_taste`.\n",
    "  \n",
    "\n",
    "> From a Decision Tree model, input feature importance weight perspective:  \n",
    "  \n",
    "> - The **greatest feature importance** to predict `review_overall` is `review_taste`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---  \n",
    "    \n",
    "# Additional Math/Coding Question (unrelated to the data)  \n",
    "  \n",
    "## Overview: A die is sold for cheaters which has 6 faces that are weighted unevenly so that the probability of rolling each number is not uniform. The probability of rolling each number is given in the table below.  \n",
    "  \n",
    "\n",
    "| \\#  | Probability |\n",
    "|-----|-------------|\n",
    "|  1  |     0.34    |\n",
    "|  2  |     0.18    |\n",
    "|  3  |     0.05    |\n",
    "|  4  |     0.18    |\n",
    "|  5  |     0.13    |\n",
    "|  6  |     0.12    |\n",
    " \n",
    "## 4. Generate 10,000 samples using only a built-in uniform random number generator (and no other packages), from the distribution above. Explain why your approach works and illustrate with graphic(s) where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### GENERATE RANDOM SAMPLES ###\n",
    "\n",
    "# Create an empty list to hold the samples:\n",
    "samples = []\n",
    "generated = []\n",
    "\n",
    "# Define a 'roll' function:\n",
    "def roll(n, bias):\n",
    "    \n",
    "    # Continue running the function until 'n' samples are generated:\n",
    "    while len(samples) < n:\n",
    "\n",
    "        # Draw from a random, uniform distribution between [0, 1):\n",
    "        randUniform = np.random.uniform()\n",
    "        generated.append(randUniform)\n",
    "\n",
    "        # Keep track of the 'bias_sum' of the bias, which has a max of 1:\n",
    "        bias_sum = 0\n",
    "        \n",
    "        # Define the side of the die:\n",
    "        side_value = 1\n",
    "        \n",
    "        # Loop through the respective roll outcome probabilities:\n",
    "        for prob in bias:\n",
    "            \n",
    "            # Add the probability of the side to the running sum:\n",
    "            bias_sum += prob\n",
    "            \n",
    "            # Check if the random value is less than the running sum:\n",
    "            if randUniform < bias_sum:\n",
    "                \n",
    "                # Add this side's value to the list of samples & \n",
    "                # continue with the rest of the function:\n",
    "                samples.append(side_value)\n",
    "                break\n",
    "            \n",
    "            # Otherwise, increment to the next side of the die & loop \n",
    "            # again:\n",
    "            side_value += 1\n",
    "     \n",
    "    # Return the 'n' number of samples:\n",
    "    return samples\n",
    "            \n",
    "# Define the number of roles:\n",
    "n = 10000\n",
    "\n",
    "# Specify the biased roll probabilities:\n",
    "bias = (0.34, 0.18, 0.05, 0.18, 0.13, 0.12)\n",
    "\n",
    "# Perform the 'roll' function & verify the length of the sample:\n",
    "samp = roll(n, bias)\n",
    "print('Length of sample: ', len(samp))\n",
    "\n",
    "# Create a DataFrame of the sample:\n",
    "roll_df = pd.DataFrame([pd.Series(samp).value_counts(), \n",
    "                        pd.Series(samp).value_counts() / n]\n",
    "                      ).T.reset_index().sort_values('index')\n",
    "roll_df.columns = ['die_value', 'counts', 'percentage']\n",
    "roll_df['expected_prob'] = bias\n",
    "\n",
    "# Calculate mean-squared error:\n",
    "mse = '{:.2e}'.format(mean_squared_error(roll_df.percentage, roll_df.expected_prob))\n",
    "print('Mean-Squared Error: ', mse)\n",
    "\n",
    "# Print `roll_df`:\n",
    "roll_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PLOT ALL GENERATED VALUES ###\n",
    "\n",
    "# Use pre-specified plotting parameters:\n",
    "plt_format()\n",
    "\n",
    "sns.distplot(generated, kde=True, fit=uniform, \n",
    "             hist_kws = {'color': '#01665e', 'alpha': 0.2},\n",
    "             kde_kws={'color': '#8c510a', 'linewidth': 4, 'label': 'Kernel Density Estimation'}, \n",
    "             fit_kws={'linewidth': 4, 'label': 'Uniform Distribution'})\n",
    "plt.title('Probability Distribution of Values Generated\\nfrom a Random, Uniform Distribution')\n",
    "plt.xlabel('Generated Float Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PLOT SAMPLE ROLL OUTCOMES ###\n",
    "\n",
    "# Use pre-specified plotting parameters:\n",
    "plt_format()\n",
    "\n",
    "sns.distplot(samp, hist_kws = {'color': '#5ab4ac'}, kde_kws={'color': '#8c510a'})\n",
    "plt.title('Probability Distribution of Random Sample Output\\nfor a Biased Die')\n",
    "plt.xlabel('Face Value of Die')\n",
    "plt.ylabel('Probability Density');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PLOT SAMPLE PROPOTIONS ###\n",
    "\n",
    "# Use pre-specified plotting parameters:\n",
    "plt_format()\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "\n",
    "pts1, = plt.plot(roll_df.die_value, roll_df.percentage, 'o', \n",
    "                 markersize=20, color='#67a9cf', alpha=0.8, \n",
    "                 markeredgecolor='k', markeredgewidth=1)\n",
    "pts2, = plt.plot(roll_df.die_value, roll_df.expected_prob, 'o', \n",
    "                 markersize=20, color='#ef8a62', alpha=0.8)\n",
    "pts3, = plt.plot(roll_df.die_value, roll_df.expected_prob, '.', \n",
    "                 markersize=5, color='k')\n",
    "plt.title('Actual & Expected Sample Die Value Proportions\\nwith MSE Calculation')\n",
    "plt.xlim(0.1, 6.9)\n",
    "plt.xlabel('Face Value of Die')\n",
    "plt.ylim(0.0, 0.36)\n",
    "plt.ylabel('Proportion of Sample')\n",
    "\n",
    "\n",
    "# Add mean-squared error value & legend to the plot:\n",
    "at = AnchoredText('Mean-Squared Error: %s' % mse, prop=dict(size=18), \n",
    "                  frameon=True, loc=3)\n",
    "at.patch.set_boxstyle(\"round, pad=0.0, rounding_size=0.2\")\n",
    "ax.add_artist(at)\n",
    "plt.legend([pts1, (pts2, pts3)], \n",
    "           ['Percentage of Sample', 'Expected Probability'], \n",
    "           markerscale=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APPROACH EXPLANATION:**  \n",
    "  \n",
    "> An *unbiased*, 6-faced die yields each face value one through six with equal probability, or a $\\frac{1}{6}$ chance of rolling any face.  This is a [discrete, uniform distribution](https://en.wikipedia.org/wiki/Discrete_uniform_distribution), meaning that the random variable given as the result of the roll is distributed equally against all possible results of the die roll, one through six.\n",
    "  \n",
    "> The [`np.random.uniform()` command](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.uniform.html) generates random samples from a uniform distribution (choosing floats in $[0, 1)$) and is the only package utilized to answer this question.  The uniform distribution is divided into six equal sections between $[0, 1)$, such as:  \n",
    "  \n",
    "> - $[0, \\frac{1}{6})$  \n",
    "  \n",
    "\n",
    "> - $[\\frac{1}{6}, \\frac{2}{6})$  \n",
    "  \n",
    "\n",
    "> - $[\\frac{2}{6}, \\frac{3}{6})$  \n",
    "  \n",
    "\n",
    "> - $[\\frac{3}{6}, \\frac{4}{6})$  \n",
    "  \n",
    "\n",
    "> - $[\\frac{4}{6}, \\frac{5}{6})$  \n",
    "  \n",
    "\n",
    "> - $[\\frac{5}{6}, 1)$  \n",
    "  \n",
    "\n",
    "> To simulate a *biased* die, the uniform distribution will need to be divided into six sections between $[0, 1)$, but this time giving each section the defined probability, such as:  \n",
    "  \n",
    "> - $[0, 0.34)$  \n",
    "  \n",
    "\n",
    "> - $[0.34, 0.34 + 0.18) = [0.34, 0.52)$  \n",
    "  \n",
    "\n",
    "> - $[0.52, 0.52 + 0.05) = [0.52, 0.57)$  \n",
    "  \n",
    "\n",
    "> - $[0.57, 0.57 + 0.18) = [0.57, 0.75)$  \n",
    "  \n",
    "\n",
    "> - $[0.75, 0.75 + 0.13) = [0.75, 0.88)$  \n",
    "  \n",
    "\n",
    "> - $[0.88, 0.88 + 0.12) = [0.88, 1)$  \n",
    "  \n",
    "\n",
    "> When looking at the information about a [continuous, uniform distribution](https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)), the cumulative probability function will not be composed of six equal-length parts but rather of six parts which differ in length according to the probability bias assigned to this die.  \n",
    "  \n",
    "\n",
    "**ANSWER:**  \n",
    "  \n",
    "> As requested in the question, I've completed the following points:  \n",
    "  \n",
    "> - Counted that exactly $10,000$ samples were generated  \n",
    "  \n",
    "\n",
    "> - Only used a uniform random number generator and no other packages  \n",
    "  \n",
    "\n",
    "> - Verified that *all* the numbers generated fit a random, uniform distribution  \n",
    "  \n",
    "\n",
    "> - Checked that they fit the distribution specified by printing a table with the sample value percentages and the expected proportions  \n",
    "  \n",
    "\n",
    "> - Plotted the distribution of the sample, which aligns with the specified proportions  \n",
    "  \n",
    "\n",
    "> - Plotted the actual vs. expected sample proportion values & calculated the mean-squared error (MSE), which was very small  \n",
    "\n",
    "\n",
    "> - Explained my approach, how it works, calculated the MSE, and illustrated with graphic as appropriate  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
